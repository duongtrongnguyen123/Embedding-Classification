{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0bba00",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LogisticRegressionScratch' from 'LogisticRegression' (/Users/hduong/Documents/foundation of AI/homeWork/spam/srcs/LogisticRegression.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_recall_curve, average_precision_score \n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLogisticRegression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegressionScratch\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'LogisticRegressionScratch' from 'LogisticRegression' (/Users/hduong/Documents/foundation of AI/homeWork/spam/srcs/LogisticRegression.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score \n",
    "from LogisticRegression import LogisticRegressionScratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a1dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(s : str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"<[^>]+>\", \" \", s)\n",
    "    s = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", s)\n",
    "    s = re.sub(r\"\\+?\\d[\\d\\-\\s]{6,}\\d\", \" \", s)\n",
    "    s = re.sub(r\"\\d+\", \" <num> \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce915f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path: str):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.dropna(subset=[\"Body\", \"Label\"])\n",
    "    X = df[\"Body\"].tolist()\n",
    "    y = df[\"Label\"].to_numpy()\n",
    "    return X, y, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50554314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(mode = \"word\"):\n",
    "    if mode == \"word\":\n",
    "        tfidf = TfidfVectorizer(\n",
    "                lowercase = False,\n",
    "                ngram_range = (1, 2),\n",
    "                max_df = 0.95,\n",
    "                min_df = 2,\n",
    "                sublinear = True\n",
    "        )\n",
    "        clf = LogisticRegressionScartch(\n",
    "            n_iters=2000,\n",
    "            reg_lambda=2.0,\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        return Pipeline([(\"tfidf\", tfidf)], [(\"clf\", clf)])\n",
    "    if mode == \"char\":\n",
    "        tfidf = TfidfVectorizer(\n",
    "            analyzer=\"char_wb\",\n",
    "            ngram_range = (3, 5),\n",
    "            max_df = 0.95,\n",
    "            min_df = 2,\n",
    "            sublinear = True\n",
    "        )\n",
    "        clf = LogisticRegressionScratch(\n",
    "            max_iter=2000,\n",
    "            C=2.0,\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        return Pipeline([(\"tfidf\", tfidf), (\"clf\", clf)])\n",
    "    else: raise ValueError(\"must be word or char\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, proba, thr=0.5, title=\"\"):\n",
    "    y_pred = (proba >= thr).astype(int)\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "    print(\"Confusion matrix: \\n\", confusion_matrix(y_true, y_pred))\n",
    "    pr_auc = average_precision_score(y_true, proba)\n",
    "    print(\"PR-AUC: %.4f\" % pr_auc)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, proba)\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label=f\"PR curve (AP={pr_auc:.3f})\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"Precision-Recall {title}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ddc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-dl)",
   "language": "python",
   "name": "ml-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
